{
  "title": "Measuring response time for web requests in a WSGI application.",
  "content": "The first topic I want to cover as part of my planned research for a possible upcoming PyCon talk titled '[Using benchmarks to understand how WSGI servers work](http://blog.dscpl.com.au/2015/05/using-benchmarks-to-understand-how-wsgi.html)' is how can one measure the response time of a web request being handled by a web application.\n\nAs far as benchmarks go this is usually done from the perspective of the tool used to generate the web requests. This is though a very gross value, incorporating not just the time spent in the WSGI application, but also network overheads and the time in any underlying or front end web server.\n\nAlthough this is still a useful measure, it doesn't actually help you to identify where the time is being spent and as a consequence isn't particularly helpful for understanding whether you have configured the system in the best possible way to remove overheads.\n\nAs a first step in trying to get more fine grained timing information about where time is being spent for a web request, I want to look at what can be done to track the amount of time spent in the WSGI application itself.\n\n# Timing of function calls\n\nThe obvious quick solution people reach for to track the amount of time spent in a function call in Python is to place a timing decorator on the function. The decorator would apply a wrapper which would remember at what time the function call started and then dump out how long it took when it exited.\n\nUsing the [wrapt](http://wrapt.readthedocs.org) package to create the decorator this could be implemented as:\n\n> \n>     from __future__ import print_function\n>     \n>     \n>     from wrapt import decorator  \n>     > from timeit import default_timer\n>     \n>     \n>     @decorator  \n>     > def timed_function(wrapped, instance, args, kwargs):  \n>     >     start = default_timer()  \n>     >     print('start', wrapped.__name__)\n>     \n>     \n>         try:  \n>     >         return wrapped(*args, **kwargs)\n>     \n>     \n>         finally:  \n>     >         duration = default_timer() - start  \n>     >         print('finish %s %.3fms' % (wrapped.__name__, duration*1000.0))\n\nFor this implementation we are using 'timeit.default\\_timer\\(\\)' as the clock source as it will ensure we use as high a resolution clock as possible for a specific platform.\n\nIn the case of a WSGI application we could then apply this to the callable entry point.\n\n> \n>     from timer1 import timed_function\n>     \n>     \n>     @timed_function  \n>     > def application(environ, start_response):  \n>     >     status = '200 OK'  \n>     >     output = b'Hello World!'\n>     \n>     \n>         response_headers = [('Content-type', 'text/plain'),  \n>     >             ('Content-Length', str(len(output)))]  \n>     >     start_response(status, response_headers)\n>     \n>     \n>         return [output]\n\nRunning this WSGI application with any WSGI server we would then get something like:\n\n> \n>     start application  \n>     > finish application 0.030ms\n\nThe time of 0.03 milliseconds for a 'Hello World\\!' application seems to be in the right order of magnitude, but is the decorator truly sufficient. Lets test out a few more simple WSGI applications.\n\nFirst up lets just add a 'sleep\\(\\)' call into the WSGI application. With the response time of our most simple of cases being so small, if we sleep for a sizeable amount of time, then that base overhead should be lost as noise within the longer sleep time.\n\n> \n>     from timer1 import timed_function  \n>     > from time import sleep\n>     \n>     \n>     @timed_function  \n>     > def application(environ, start_response):  \n>     >     status = '200 OK'  \n>     >     output = b'Hello World!'\n>     \n>     \n>         response_headers = [('Content-type', 'text/plain'),  \n>     >         ('Content-Length', str(len(output)))]  \n>     >     start_response(status, response_headers)\n>     \n>     \n>         sleep(1.0)\n>     \n>     \n>         return [output]\n\nTrigger a web request with this WSGI application and we get:\n\n> \n>     start application  \n>     > finish application 1000.653ms\n\nAnd so the result is closer to the much longer sleep time as we expected.\n\nIf we take away the sleep time we end up with 0.653 milliseconds which does seem quite high compared to what we had previously. The reason for this though is likely to be the operating system overheads of waking up the process from its short sleep and resuming execution. The resulting time therefore is still reasonable.\n\nNow in both these examples the WSGI application returned an iterable which was a list of strings. In other words the complete response was returned in one go after being generated up front.\n\nAnother way of writing a WSGI application is as a generator. That is, rather than returning all values at one time as a list, we yield each specific value making up the response. This allows the response to be generated as it is being returned.\n\n> \n>     from timer1 import timed_function  \n>     > from time import sleep\n>     \n>     \n>     @timed_function  \n>     > def application(environ, start_response):  \n>     >     status = '200 OK'  \n>     >     output = b'Hello World!'\n>     \n>     \n>         response_headers = [('Content-type', 'text/plain'),  \n>     >             ('Content-Length', str(len(output)))]  \n>     >     start_response(status, response_headers)\n>     \n>     \n>         sleep(1.0)\n>     \n>     \n>         yield output\n\nWe again trigger a web request and the result this time is:\n\n> \n>     start application  \n>     > finish application 0.095ms\n\nIn this case we are back to a sub millisecond value again for time, so obviously there is a problem with our decorator in this case.\n\nThe problem here is that as the WSGI application is a generator function, the decorator is only timing how long it took for the Python interpreter to create the generator object. The time will not actually include the execution of any code within the generator function.\n\nThis is the case because the initial code in the function, including the 'sleep\\(\\)' call, will only be executed upon the first attempt to fetch a value from the generator object. This is something that will only be done by the WSGI server after the generator object has been returned and the wrapper applied by the decorator has also exited.\n\nThe traditional method of using a decorator with before and after actions executed either side of the call of the wrapped function will not therefore work for a WSGI application which is implemented as a generator function.\n\nThere are actually other situations besides a generator function which will also fail as there are in fact numerous ways that a WSGI application callable object can be implemented. Any scenario which defers work until the point when the iterable returned is being consumed will not yield the correct results with our first attempt at a timing decorator.\n\nIf interested in the various ways that WSGI application callable objects can be implemented, you can read a previous post I wrote on the topic called '[Implementing WSGI application objects](http://blog.dscpl.com.au/2011/01/implementing-wsgi-application-objects.html)'.\n\n# Marking the end of a request\n\nThe solution to our problem with not being able to use a traditional function timing decorator can be found within the [WSGI](https://www.python.org/dev/peps/pep-3333/) protocol specification itself. Specifically it is stated in the specification:\n\n> _If the iterable returned by the application has a close\\(\\) method, the server or gateway must call that method upon completion of the current request, whether the request was completed normally, or terminated early due to an application error during iteration or an early disconnect of the browser. \\(The close\\(\\) method requirement is to support resource release by the application. This protocol is intended to complement PEP 342 's generator support, and other common iterables with close\\(\\) methods.\\)_\n\nWhat this means is that where the iterable from the WSGI application would otherwise be returned, we can instead return a wrapper object around that iterable and in our wrapper provide a 'close\\(\\)' method. This 'close\\(\\)' method is then guaranteed to be called at the end of the request regardless of whether it completes successfully or not.\n\nWe can therefore use this as the place for ending the timing of the request where the iterable was returned. One requirement in using such a wrapper though is that the wrapper itself must in turn call the 'close\\(\\)' method of any iterable which was wrapped to preserve any expectation it has that its own 'close\\(\\)' method is called.\n\n> \n>     from __future__ import print_function\n>     \n>     \n>     from wrapt import decorator, ObjectProxy  \n>     > from timeit import default_timer  \n>     >   \n>     > class WSGIApplicationIterable1(ObjectProxy):\n>     \n>     \n>         def __init__(self, wrapped, name, start):  \n>     >         super(WSGIApplicationIterable1, self).__init__(wrapped)  \n>     >         self._self_name = name  \n>     >         self._self_start = start\n>     \n>     \n>         def close(self):  \n>     >         if hasattr(self.__wrapped__, 'close'):  \n>     >             self.__wrapped__.close()\n>     \n>     \n>             duration = default_timer() - self._self_start  \n>     >         print('finish %s %.3fms' % (self._self_name, duration*1000.0))\n>     \n>     \n>     @decorator  \n>     > def timed_wsgi_application1(wrapped, instance, args, kwargs):  \n>     >     name = wrapped.__name__\n>     \n>     \n>         start = default_timer()  \n>     >     print('start', name)\n>     \n>     \n>         try:  \n>     >         return WSGIApplicationIterable1(wrapped(*args, **kwargs), name, start)\n>     \n>     \n>         except:  \n>     >         duration = default_timer() - start  \n>     >         print('finish %s %.3fms' % (name, duration*1000.0))  \n>     >         raise\n\nIn the implementation of the wrapper for the WSGI application iterable I have used the 'ObjectProxy' class from the wrapt package. The 'ObjectProxy' class in this case acts as a transparent object proxy for whatever is wrapped. That is, any action on the proxy object will be performed on the wrapped object unless that action is somehow overridden in the proxy object. So in this case we have overridden the 'close\\(\\)' method to allow us to insert our code for stopping the timer.\n\nThis wrapper class could have been implemented as a standalone class without relying on the 'ObjectProxy' class from wrapt, however using 'ObjectProxy' from wrapt brings some benefits which will be covered in a subsequent blog post.\n\nUsing this new decorator our test example is:\n\n> \n>     from timer1 import timed_wsgi_application1  \n>     > from time import sleep\n>     \n>     \n>     @timed_wsgi_application1  \n>     > def application(environ, start_response):  \n>     >     status = '200 OK'  \n>     >     output = b'Hello World!'\n>     \n>     \n>         response_headers = [('Content-type', 'text/plain'),  \n>     >             ('Content-Length', str(len(output)))]  \n>     >     start_response(status, response_headers)\n>     \n>     \n>         sleep(1.0)\n>     \n>     \n>         yield output\n\nWhen a web request is now issued we get:\n\n> \n>     start application  \n>     > finish application 1000.593ms\n\nThis is now the result we are expecting.\n\nJust to make sure that we are preserving properly the semantics for 'close\\(\\)' being called, we can use the test example of:\n\n> \n>     from __future__ import print_function\n>     \n>     \n>     from timer1 import timed_wsgi_application1  \n>     > from time import sleep\n>     \n>     \n>     class Iterable(object):  \n>     >   \n>     >     def __init__(self, output):  \n>     >         self.output = output\n>     \n>     \n>         def __iter__(self):  \n>     >         return self\n>     \n>     \n>         def next(self):  \n>     >         try:  \n>     >             return self.output.pop(0)  \n>     >         except IndexError:  \n>     >             raise StopIteration\n>     \n>     \n>         def close(self):  \n>     >         print('close')\n>     \n>     \n>     @timed_wsgi_application1  \n>     > def application(environ, start_response):  \n>     >     status = '200 OK'  \n>     >     output = b'Hello World!'\n>     \n>     \n>         response_headers = [('Content-type', 'text/plain'),  \n>     >             ('Content-Length', str(len(output)))]  \n>     >     start_response(status, response_headers)\n>     \n>     \n>         sleep(1.0)\n>     \n>     \n>         return Iterable([output])\n\nWhat is being done here is that rather than returning a list or using a generator function, we return an iterable implemented as a class object. This iterable object defines a 'close\\(\\)' method.\n\nIf we use this test example the result is:\n\n> \n>     start application  \n>     > close  \n>     > finish application 1000.851ms\n\nThat 'close' is displayed means that when the WSGI server calls the 'close\\(\\)' method on the result from our WSGI application timing decorator, that we are in turn correctly then calling the 'close\\(\\)' method of the iterable that was originally returned by the WSGI application.\n\n# Applying the timing decorator\n\nWe now have a timing decorator that can be applied to a WSGI application and which will correctly time from the start of when the WSGI application callable object was executed, until the point where all the response content had been written back to a client and any custom 'close\\(\\)' method of the iterable, if one exists, was called.\n\nIn the next few blog posts I will start applying this timing decorator to WSGI applications which do more than return just 'Hello World\\!' to see if anything can be learned about the characteristics of the most popular WSGI servers being used under different use cases.\n\nThe intent of exploring the different use cases is to show why benchmarks using a single simple test case aren't sufficient to properly evaluate which WSGI server may be the best for you. Rely on such simple tests and you could well make the wrong choice and end up using a WSGI server that doesn't perform as well as alternatives for your specific use case.",
  "date": "Friday, May 15, 2015",
  "author": "Graham Dumpleton",
  "url": "http://blog.dscpl.com.au/2015/05/measuring-response-time-for-web.html",
  "post_id": "4029927534251797636",
  "blog_id": "2363643920942057324",
  "comments": [
    {
      "comment_id": "6415922404029610583",
      "author": "Max Ludwig",
      "author_url": "https://www.blogger.com/profile/08420310375661786940",
      "author_profile_id": "08420310375661786940",
      "content": "Is there any reason why Apache itself shouldn't do that?",
      "timestamp": "May 16, 2015 at 2:23 AM",
      "permalink": "http://blog.dscpl.com.au/2015/05/measuring-response-time-for-web.html?showComment=1431707022144#c6415922404029610583",
      "is_blog_author": false
    },
    {
      "comment_id": "3680710683834562393",
      "author": "Graham Dumpleton",
      "author_url": "https://www.blogger.com/profile/13609779138164842374",
      "author_profile_id": "13609779138164842374",
      "content": "@Max That isn't going to help if running gunicorn, uWSGI or Tornado. I will be exploring what monitoring capabilities some WSGI servers have built in, but this is intended to be applicable to any WSGI server. There are also other things about the interaction with the WSGI layer and web server that I also want to track which aren't readily obtained from information which may be recorded by the web server alone.",
      "timestamp": "May 16, 2015 at 7:39 AM",
      "permalink": "http://blog.dscpl.com.au/2015/05/measuring-response-time-for-web.html?showComment=1431725980188#c3680710683834562393",
      "is_blog_author": true
    }
  ],
  "labels": [
    "decorators",
    "python",
    "wrapt",
    "wsgi"
  ],
  "metadata": {
    "published_timestamp": "2015-05-15T19:00:00+10:00",
    "blog_title": "Graham Dumpleton",
    "page_title": "Graham Dumpleton: Measuring response time for web requests in a WSGI application.",
    "og_title": "Measuring response time for web requests in a WSGI application.",
    "og_description": "The first topic I want to cover as part of my planned research for a possible upcoming PyCon talk titled ' Using benchmarks to understand ho...",
    "og_url": "http://blog.dscpl.com.au/2015/05/measuring-response-time-for-web.html"
  },
  "downloaded_images": []
}
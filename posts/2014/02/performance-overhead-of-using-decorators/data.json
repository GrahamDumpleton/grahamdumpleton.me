{
  "title": "Performance overhead of using decorators.",
  "content": "This is the ninth post in my series of blog posts about Python decorators and how I believe they are generally poorly implemented. It follows on from the previous post titled '[The @synchronized decorator as context manager](/posts/2014/01/the-synchronized-decorator-as-context/)', with the very first post in the series being '[How you implemented your Python decorator is wrong](/posts/2014/01/how-you-implemented-your-python/)'.  \n  \nThe posts so far in this series were bashed out in quick succession in a bit over a week. Because that was quite draining on the brain and due to other commitments I took a bit of a break. Hopefully I can get through another burst of posts, initially about performance considerations when implementing decorators and then start a dive into how to implement the object proxy which underlies the function wrapper the decorator mechanism described relies on.  \n  \n\n\n###  Overhead in decorating a normal function\n\n  \nIn this post I am only going to look at the overhead of decorating a normal function with the decorator mechanism which has been described. The relevant part of the decorator mechanism which comes into play in this case is:  \n\n\n> class function\\_wrapper\\(object\\_proxy\\): \n\n> def \\_\\_init\\_\\_\\(self, wrapped, wrapper\\):  \n>  super\\(function\\_wrapper, self\\).\\_\\_init\\_\\_\\(wrapped\\)  \n>  self.wrapper = wrapper  \n>  ...\n\n> def \\_\\_get\\_\\_\\(self, instance, owner\\):  \n>  ...\n\n> def \\_\\_call\\_\\_\\(self, \\*args, \\*\\*kwargs\\):  \n>  return self.wrapper\\(self.wrapped, None, args, kwargs\\) \n\n> def decorator\\(wrapper\\):  \n>  def \\_wrapper\\(wrapped, instance, args, kwargs\\):  \n>  def \\_execute\\(wrapped\\):  \n>  if instance is None:  \n>  return function\\_wrapper\\(wrapped, wrapper\\)  \n>  elif inspect.isclass\\(instance\\):  \n>  return function\\_wrapper\\(wrapped, wrapper.\\_\\_get\\_\\_\\(None, instance\\)\\)  \n>  else:  \n>  return function\\_wrapper\\(wrapped, wrapper.\\_\\_get\\_\\_\\(instance, type\\(instance\\)\\)\\)  \n>  return \\_execute\\(\\*args, \\*\\*kwargs\\)  \n>  return function\\_wrapper\\(wrapper, \\_wrapper\\)\n\nIf you want to refresh your memory of the complete code that was previously presented you can check back to the [last post](/posts/2014/01/maintaining-decorator-state-using-class/) where it was described in full.  \n  \nWith our decorator factory, when creating a decorator and then decorating a normal function with it we would use:  \n\n\n> @decorator  \n>  def my\\_function\\_wrapper\\(wrapped, instance, args, kwargs\\):  \n>  return wrapped\\(\\*args, \\*\\*kwargs\\) \n\n> @my\\_function\\_wrapper  \n>  def function\\(\\):  \n>  pass\n\nThis is in contrast to the same decorator created in the more traditional way using a function closure.  \n\n\n> def my\\_function\\_wrapper\\(wrapped\\):  \n>  def \\_my\\_function\\_wrapper\\(\\*args, \\*\\*kwargs\\):  \n>  return wrapped\\(\\*args, \\*\\*kwargs\\)  \n>  return \\_my\\_function\\_wrapper \n\n> @my\\_function\\_wrapper  \n>  def function\\(\\):  \n>  pass\n\nNow what actually occurs in these two different cases when we make the call:  \n\n\n> function\\(\\)\n\n  \n\n\n###  Tracing the execution of the function\n\n  \nIn order to trace the execution of our code we can use Python's profile hooks mechanism.  \n\n\n> import sys \n\n> def tracer\\(frame, event, arg\\):  \n>  print\\(frame.f\\_code.co\\_name, event\\) \n\n> sys.setprofile\\(tracer\\) \n\n> function\\(\\)\n\nThe purpose of the profile hook is to allow you to register a callback function which is called on the entry and exit of all functions. Using this was can trace the sequence of function calls that are being made.  \n  \nFor the case of a decorator implemented as a function closure this yields:  \n\n\n> \\_my\\_function\\_wrapper call  \n>  function call  \n>  function return  \n>  \\_my\\_function\\_wrapper return\n\nSo what we see here is that the nested function of our function closure is called. This is because the decorator in the case of a using a function closure is replacing 'function' with a reference to that nested function. When that nested function is called, it then in turn calls the original wrapped function.  \n  \nFor our implementation using our decorator factory, when we do the same thing we instead get:  \n\n\n> \\_\\_call\\_\\_ call  \n>  my\\_function\\_wrapper call  \n>  function call  \n>  function return  \n>  my\\_function\\_wrapper return  \n>  \\_\\_call\\_\\_ return\n\nThe difference here is that our decorator replaces 'function' with an instance of our function wrapper class. Being a class, when it is called as if it was a function, the \\_\\_call\\_\\_\\(\\) method is invoked on the instance of the class. The \\_\\_call\\_\\_\\(\\) method is then invoking the user supplied wrapper function, which in turn calls the original wrapped function.  \n  \nThe result therefore is that we have introduced an extra level of indirection, or in other words an extra function call into the execution path.  \n  \nKeep in mind though that \\_\\_call\\_\\_\\(\\) is actually a method though and not just a normal function. Being a method that means there is actually a lot more work going on behind the scenes than a normal function call. In particular, the unbound method needs to be bound to the instance of our function wrapper class before it can be called. This doesn't appear in the trace of the calls, but it is occurring and that will incur additional overhead.  \n  \n\n\n###  Timing the execution of the function\n\n  \nBy performing the trace above we know that our solution incurs an additional method call overhead. How much actual extra overhead is this resulting in though?  \n  \nTo try and measure the increase in overhead in each solution we can use the 'timeit' module to time the execution of our function call. As a baseline, we first want to time the call of a function without any decorator applied.  \n\n\n> \\# benchmarks.py \n\n> def function\\(\\):  \n>  pass \n\nTo time this we use the command:  \n\n\n> $ python -m timeit -s 'import benchmarks' 'benchmarks.function\\(\\)'\n\nThe 'timeit' module when used in this way will perform a suitable large number of iterations of calling the function, divide the resulting total time for all calls with the count of the number and end up with a time value for a single call.  \n  \nFor a 2012 model MacBook Pro this yields:  \n\n\n> 10000000 loops, best of 3: 0.132 usec per loop\n\nNext up is to try with a decorator implemented as a function closure. For this we get:  \n\n\n> 1000000 loops, best of 3: 0.326 usec per loop\n\nAnd finally with our decorator factory:  \n\n\n> 1000000 loops, best of 3: 0.771 usec per loop\n\nIn this final case, rather than use the exact code as has been presented so far in this series of blog posts, I have used the 'wrapt' module implementation of what has been described. This implementation works slightly differently as it has a few extra capabilities over what has been described and the design is also a little bit different. The overhead will still be roughly equivalent and if anything will cast things as being slightly worse than the more minimal implementation.  \n  \n\n\n###  Speeding up execution of the wrapper\n\n  \nAt this point no doubt there will be people wanting to point out that this so called better way of implementing a decorator is too slow to be practical to use, even if it is more correct as far as properly honouring things such as the descriptor protocol for method invocation.  \n  \nIs there therefore anything that can be done to speed up the implementation?  \n  \nThat is of course a stupid question for me to be asking because you should realise by now that I would find a way. :-\\)  \n  \nThe path that can be taken at this point is to implement everything that has been described for the function wrapper and object proxy as a Python C extension module. For simplicity we can keep the decorator factory itself implemented as pure Python code as execution of that is not time critical as it would only be invoked once when the decorator is applied to the function and not on every call of the decorated function.  \n  \nOne thing I am definitely not going to do is blog about how to go about implementing the function wrapper and object proxy as a Python C extension module. Rest assured though that it works in the same way as the parallel pure Python implementation. It does obviously though run a lot quicker due to being implemented as C code using the Python C APIs rather than as pure Python code.  \n  \nWhat is the result then by implementing the function wrapper and object proxy as a Python C extension module? It is:  \n\n\n> 1000000 loops, best of 3: 0.382 usec per loop\n\nSo although a lot more effort was required in actually implementing the function wrapper and object proxy as a Python C extension module, the effort was well worth it, with the results now being very close to the implementation of the decorator that used a function closure.  \n  \n  \n\n\n###  Normal functions vs methods of classes\n\n  \nSo far we have only considered the case of decorating a normal function. As expected, due to the introduction of an extra level of indirection as well as the function wrapper being implemented as a class, overhead was notably more. Albeit, that it was still in the order of only half a microsecond.  \n  \nAll the same, we were able to speed things up to a point, by implementing our function wrapper and object proxy as C code, where the overhead above that of a decorator implemented as a function closure was negligible.  \n  \nWhat now about where we decorate methods of a class. That is, instance methods, class methods and static methods. For that you will need to wait until the next blog post in this series on decorators.",
  "date": "Saturday, February 8, 2014",
  "author": "Graham Dumpleton",
  "url": "http://blog.dscpl.com.au/2014/02/performance-overhead-of-using-decorators.html",
  "post_id": "8465155282604465872",
  "blog_id": "2363643920942057324",
  "comments": [
    {
      "comment_id": "177524660707228404",
      "author": "Alexander",
      "author_url": "https://www.blogger.com/profile/16457251664894681382",
      "author_profile_id": "16457251664894681382",
      "content": "Have you considered using function that does something rather then empty one?",
      "timestamp": "February 16, 2014 at 12:37 AM",
      "permalink": "http://blog.dscpl.com.au/2014/02/performance-overhead-of-using-decorators.html?showComment=1392471434741#c177524660707228404",
      "is_blog_author": false
    },
    {
      "comment_id": "7519024256674104968",
      "author": "Graham Dumpleton",
      "author_url": "https://www.blogger.com/profile/13609779138164842374",
      "author_profile_id": "13609779138164842374",
      "content": "How would that help or make a difference?  \n  \nThe point of the exercise is to try and quantify how much extra base overhead there is to using this approach to implementing a decorator. As soon as you have the function being wrapped doing actual work, then that extra overhead quickly goes down as a percentage of the total cost of calling the wrapped function and ends up being indistinguishable noise.  \n  \nSo, for functions which are already expensive to call, adding a decorator isn't going to make any real difference. So it is more important to look towards where the function is intended to be as quick as possible as people get concerned about the cumulative overhead of having a decorator if such a function is called a large number of times. This is especially the case for high performance web applications where people have a web application and are after response times in milliseconds.  \n  \nThe impact of any overhead will become more apparent when I get a chance to do the followup post which looks at the overhead of applying a decorator to a method of a class.",
      "timestamp": "February 17, 2014 at 10:09 AM",
      "permalink": "http://blog.dscpl.com.au/2014/02/performance-overhead-of-using-decorators.html?showComment=1392592147668#c7519024256674104968",
      "is_blog_author": true
    },
    {
      "comment_id": "4221573034603455628",
      "author": "A. Jesse Jiryu Davis",
      "author_url": "https://www.blogger.com/profile/08612435176546178055",
      "author_profile_id": "08612435176546178055",
      "content": "A great article in a fantastic series of articles. This whole analysis of decorators is a substantial contribution to the field.",
      "timestamp": "March 25, 2014 at 4:33 AM",
      "permalink": "http://blog.dscpl.com.au/2014/02/performance-overhead-of-using-decorators.html?showComment=1395682385048#c4221573034603455628",
      "is_blog_author": false
    }
  ],
  "labels": [
    "decorators",
    "python"
  ],
  "metadata": {
    "published_timestamp": "2014-02-08T22:42:00+11:00",
    "blog_title": "Graham Dumpleton",
    "page_title": "Graham Dumpleton: Performance overhead of using decorators.",
    "og_title": "Performance overhead of using decorators.",
    "og_description": "This is the ninth post in my series of blog posts about Python decorators and how I believe they are generally poorly implemented. It follow...",
    "og_url": "http://blog.dscpl.com.au/2014/02/performance-overhead-of-using-decorators.html"
  },
  "downloaded_images": []
}